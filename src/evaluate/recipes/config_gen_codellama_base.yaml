# Model arguments
model_name_or_path: TheBloke/CodeLlama-7B-Instruct-GPTQ
revision: gptq-4bit-32g-actorder_True
model_name: codellama-7b-instruct

# Data arguments
dataset_name_or_path: datasets/dataset_splits
dataset_split: test
output_dir: runs/eval_results/
chat_template: "{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ message['content'] + ' [/INST]' }}\n{% elif message['role'] == 'system' %}\n{{ '[INST] ' + message['content'] }}{% elif message['role'] == 'assistant' %}{{ message['content'] }}\n{% endif %}\n{% endfor %}"

# Generation config
max_new_tokens: 1024
greedy: True
